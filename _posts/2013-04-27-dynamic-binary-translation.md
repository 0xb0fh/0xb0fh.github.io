---
layout: post
title:  "Dynamic binary translation"
date: 2013-04-27 21:06:26 +0100
categories: legacy
---
Virtualization is an interesting topic and today there is more than one solution (mostly open source) which basically populates the scene.
There are basically three ways to implement this solutions in order to execute operating systems into other operating systems:

* Full virtualization
* Paravirtualization
* Emulation

While full virtualization takes advantage of the hardware features (Virtualization extensions) provided by "today's most recent CPUs", the other two solutions rely on software in two different ways in fact both do not require virtualization extensions from the host CPU, allowing virtualization on arch that do not have Hardware-assisted virtualization extensions.

Well, the PV concept (along with hypercalls, ...) has been introduced by Xen and requires modification on the guest kernel, which is basically possible when the guest kernel is open source such as linux, freeBSD and so forth.
Emulation is also another concept that covers more than one aspect, every device could be emulated (even HVMs use devices emulation to provide I/O virtualization to the guest VMs)  and the processor is not an exception.
The overall concept of CPUs emulation is pretty straightforward to understand and the whole idea behind it, is no more than emulate the behavior of a target CPU on a host CPU. This generic definition implies that it can be possible to emulate target architecture that differ from the host architecture or even for example execute ARM binaries on x86 hosts.

CPU emulation is achieved mostly in three ways:

* interpretation
* static recompilation
* dynamic binary translation

The purpose of this post is just to have a look at the third option so I will skip the first two.
Dynamic binary translation is a process which allows to translate one binary, based on a certain instruction set (target ISA) to another (host ISA), even though one of the most common (at least the most commonly imagined) usage of the emulators is x86 to x86.

One way to dynamically translate target code into host machine code can be done using the approach used by Qemu in its earlier releases, the idea is to split instructions into small pieces of C functions called micro-ops, these generic micro ops once compiled are obviously converted into machine code so at runtime during the translation phase they can be concatenated into a buffer and later executed as well.
Let's make an example and assume we encounter the following instruction while we are translating the binary:

```asm
addw $0x02, %ax
```

the corresponding ops to the instruction can be:

```c
op_movl_T0_im();
op_addl_AX_T0();
```

defined as follow:

```c
#define R_AX ((struct x86_cpu *)env->cpu_arch)->gpr[AX]

void op_addl_AX_T0(void)
{
    R_AX += T0;
    FORCE_RET();
}
				
void op_movl_T0_im(void)
{
    T0 = ((long)(&__op_param1));
    FORCE_RET();
}
```

where *T0* is a global variable bound to the *r15* register:

```c
register unsigned long T0 asm("r15");
```

and __op_param1 is just a placeholder, in fact once the op is copied into the buffer, the corresponding bytes are filled with the immediate operand read from the target object code thus in the example those bytes will be replaced by the immediate value $0x02.

Let's see the machine code generated by gcc

```
init@void64:~/workspace/emu/dyngen/arch/x86$ objdump -d x86_op.o
0000000000000000 <op_movl_T0_im>:
0:    41 bf 00 00 00 00        mov    $0x0,%r15d
...
a:    c3                       retq

0000000000000010 <op_addl_AX_T0>:
10:    49 8b 06                 mov    (%r14),%rax
13:    66 44 01 38              add    %r15w,(%rax)
...
1b:    c3                       retq
```

Here we have to consider a couple of things, the first one is that the pointer of emu_cpu structure, which is the generic struct containing the architecture independent fields + a pointer to cpu dependent datas (gprs and so on), is declared and defined like this:

```c
struct emu_cpu {
    void           *cpu_arch;
    uint8_t		   *RAM;
    int (*start)(void);
};

...
register struct emu_cpu *env asm("r14");
```

Where cpu_arch field when initialized will contain a pointer to the following:

```c
struct x86_cpu {
    uint16_t gpr[4];
    uint16_t pc;
};
```

consindering the structs seen before the generated assembly code make perfectly sense thus the target instruction:

```asm
addw $0x02, %ax
```

will be translated into:

```asm
mov    $0x0,%r15d
mov    (%r14),%rax
add    %r15w,(%rax)
```

The first instruction doesn't need explaination, with the second what happens is ```rax := env->cpu_arch``` and the last instruction does ```cpu_arch->gpr[AX] := cpu_arch->gpr[AX]+0x0``` where the $0x0 will be replace before the execution of the buffer itself with the target immediate value simply:

```c
*(uint32_t *)(tr_chunk + 2) = param1;
```

Once everything has been disassembled and translated is copied into the "execution buffer";
the buffer is basically a struct which is initialized with a nop slide (sequence of 0x90) and with a ret opcode into the last byte (ret member):

```c
struct tb_s{ uint8_t tb[TB_MAX_SIZE]; uint8_t ret; }__attribute__((aligned(0x1000), packed));
```

The attributes packed and aligned are used respectively to tell the compiler to avoid padding between members of the struct and to align the structure to a page boundary (useful to set  the buffer as executable).

With the nop slide we are allowed to generate code smaller than the buffer so when we jump into the buffer to execute the code contained in it, the piece of code generated will be executed and when we will reach the end of the code we will slide to the ret (0xc3) instruction thus giving back to the emulator the regular control of the execution flow.

The code included is just a dummy translator so we are all set with this, but the nop slide method it's not obviously the way to go in a real system because of its inefficiency  and useless overhead avoidable.
For example putting a ret at the end of translated_bytes+1 can be a solution but other more flexible ways should be preferred and even though usually the translated block buffer is almost completely filled by generated code, actually reducing the overhead of the execution of any extra byte (nops), the memset of the whole buffer is something avoidable from the performance point of view.

Let's consider the following piece of assembly code assembled in order to generate a flat binary:

```asm
.code16gcc
.text
.globl  _start
.type   _start, @function

_start:
movw $1, %ax
movw $2, %bx

movw %ax, %bx
#  addw $0x02, %ax
#  xor %ax, %ax
retw
```

let's execute the emulator on this binary:

```sh
init@void64:~/workspace/emu/dyngen$ ./demu dyn ./test/bin/i8086.bin
Registers dump:
AX: 1, BX: 0, CX: 0, DX: 0
Registers dump:
AX: 1, BX: 2, CX: 0, DX: 0
Registers dump:
AX: 1, BX: 1, CX: 0, DX: 0
```

It works correctly with the assignment and although the mov instruction is easy to translate it would be easy enough to add new instructions to the translator.

Other challenges come from branch instructions, interrupts and other instructions as well but the purpose of the post was just to explain the overall concept of dynamic translation and explain one possible solution used in real world.
Other posts can be dedicated to this topic.

The idea behind the approach of dynamic translation described above is interesting and as you can imagine is performing because part of the translation overhead is delegated off-line to the compiler which during the compilation process just translates in a regular fashion the generic micro ops later fetched, copied (at runtime) and executed. This lightweight approach as we have seen has some pros but it also has some cons and one above all is that it is "compiler dependent", this means that considering that gcc (or any other compiler) is a generic compiler it can change its way to generate the code, introduce optimizations and so on, for this very reason we can hit some problems between different compiler versions making the system hard to maintain over the time and over compiler versions.

I will treat in another post how to generate host code with llvm's just in time compiler in order to see another approach where all the code is generated at runtime.

Source code [here]({{site.source_baseurl}}/demu)

**<<EOF**
